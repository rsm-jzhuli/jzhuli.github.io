<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jun Zhu Li">
<meta name="dcterms.date" content="2025-05-28">

<title>Multinomial Logit Model – Jun’s Website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c9f0887447d3a639491f60c4af03832d.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-dc376453fc93729a66e4175d27e645db.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jun’s Website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:jzhuuli@gmail.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/junzhuli"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#likelihood-for-the-multi-nomial-logit-mnl-model" id="toc-likelihood-for-the-multi-nomial-logit-mnl-model" class="nav-link active" data-scroll-target="#likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</a></li>
  <li><a href="#simulate-conjoint-data" id="toc-simulate-conjoint-data" class="nav-link" data-scroll-target="#simulate-conjoint-data">2. Simulate Conjoint Data</a></li>
  <li><a href="#preparing-the-data-for-estimation" id="toc-preparing-the-data-for-estimation" class="nav-link" data-scroll-target="#preparing-the-data-for-estimation">3. Preparing the Data for Estimation</a></li>
  <li><a href="#estimation-via-maximum-likelihood" id="toc-estimation-via-maximum-likelihood" class="nav-link" data-scroll-target="#estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</a></li>
  <li><a href="#estimation-via-bayesian-methods" id="toc-estimation-via-bayesian-methods" class="nav-link" data-scroll-target="#estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">6. Discussion</a>
  <ul class="collapse">
  <li><a href="#interpreting-parameter-estimates" id="toc-interpreting-parameter-estimates" class="nav-link" data-scroll-target="#interpreting-parameter-estimates">Interpreting Parameter Estimates</a></li>
  <li><a href="#toward-a-multi-level-hierarchical-model" id="toc-toward-a-multi-level-hierarchical-model" class="nav-link" data-scroll-target="#toward-a-multi-level-hierarchical-model">Toward a Multi-Level (Hierarchical) Model</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Multinomial Logit Model</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jun Zhu Li </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm.</p>
<section id="likelihood-for-the-multi-nomial-logit-mnl-model" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</h2>
<p>Suppose we have <span class="math inline">\(i=1,\ldots,n\)</span> consumers who each select exactly one product <span class="math inline">\(j\)</span> from a set of <span class="math inline">\(J\)</span> products. The outcome variable is the identity of the product chosen <span class="math inline">\(y_i \in \{1, \ldots, J\}\)</span> or equivalently a vector of <span class="math inline">\(J-1\)</span> zeros and <span class="math inline">\(1\)</span> one, where the <span class="math inline">\(1\)</span> indicates the selected product. For example, if the third product was chosen out of 3 products, then either <span class="math inline">\(y=3\)</span> or <span class="math inline">\(y=(0,0,1)\)</span> depending on how we want to represent it. Suppose also that we have a vector of data on each product <span class="math inline">\(x_j\)</span> (eg, brand, price, etc.).</p>
<p>We model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:</p>
<p><span class="math display">\[ U_{ij} = x_j'\beta + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(\epsilon_{ij}\)</span> is an i.i.d. extreme value error term.</p>
<p>The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer <span class="math inline">\(i\)</span> chooses product <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} \]</span></p>
<p>For example, if there are 3 products, the probability that consumer <span class="math inline">\(i\)</span> chooses product 3 is:</p>
<p><span class="math display">\[ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} \]</span></p>
<p>A clever way to write the individual likelihood function for consumer <span class="math inline">\(i\)</span> is the product of the <span class="math inline">\(J\)</span> probabilities, each raised to the power of an indicator variable (<span class="math inline">\(\delta_{ij}\)</span>) that indicates the chosen product:</p>
<p><span class="math display">\[ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}\]</span></p>
<p>Notice that if the consumer selected product <span class="math inline">\(j=3\)</span>, then <span class="math inline">\(\delta_{i3}=1\)</span> while <span class="math inline">\(\delta_{i1}=\delta_{i2}=0\)</span> and the likelihood is:</p>
<p><span class="math display">\[ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} \]</span></p>
<p>The joint likelihood (across all consumers) is the product of the <span class="math inline">\(n\)</span> individual likelihoods:</p>
<p><span class="math display">\[ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} \]</span></p>
<p>And the joint log-likelihood function is:</p>
<p><span class="math display">\[ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) \]</span></p>
</section>
<section id="simulate-conjoint-data" class="level2">
<h2 class="anchored" data-anchor-id="simulate-conjoint-data">2. Simulate Conjoint Data</h2>
<p>We will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.</p>
<p>Each alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.</p>
<p>The part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer <span class="math inline">\(i\)</span> for hypothethical streaming service <span class="math inline">\(j\)</span> is</p>
<p><span class="math display">\[
u_{ij} = (1 \times Netflix_j) + (0.5 \times Prime_j) + (-0.8*Ads_j) - 0.1\times Price_j + \varepsilon_{ij}
\]</span></p>
<p>where the variables are binary indicators and <span class="math inline">\(\varepsilon\)</span> is Type 1 Extreme Value (ie, Gumble) distributed.</p>
<p>The following code provides the simulation of the conjoint data.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<pre class="{r}"><code># set seed for reproducibility
set.seed(123)

# define attributes
brand &lt;- c("N", "P", "H") # Netflix, Prime, Hulu
ad &lt;- c("Yes", "No")
price &lt;- seq(8, 32, by=4)

# generate all possible profiles
profiles &lt;- expand.grid(
    brand = brand,
    ad = ad,
    price = price
)
m &lt;- nrow(profiles)

# assign part-worth utilities (true parameters)
b_util &lt;- c(N = 1.0, P = 0.5, H = 0)
a_util &lt;- c(Yes = -0.8, No = 0.0)
p_util &lt;- function(p) -0.1 * p

# number of respondents, choice tasks, and alternatives per task
n_peeps &lt;- 100
n_tasks &lt;- 10
n_alts &lt;- 3

# function to simulate one respondent’s data
sim_one &lt;- function(id) {
  
    datlist &lt;- list()
    
    # loop over choice tasks
    for (t in 1:n_tasks) {
        
        # randomly sample 3 alts (better practice would be to use a design)
        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])
        
        # compute deterministic portion of utility
        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)
        
        # add Gumbel noise (Type I extreme value)
        dat$e &lt;- -log(-log(runif(n_alts)))
        dat$u &lt;- dat$v + dat$e
        
        # identify chosen alternative
        dat$choice &lt;- as.integer(dat$u == max(dat$u))
        
        # store task
        datlist[[t]] &lt;- dat
    }
    
    # combine all tasks for one respondent
    do.call(rbind, datlist)
}

# simulate data for all respondents
conjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))

# remove values unobservable to the researcher
conjoint_data &lt;- conjoint_data[ , c("resp", "task", "brand", "ad", "price", "choice")]

# clean up
rm(list=setdiff(ls(), "conjoint_data"))</code></pre>
</div>
</div>
</div>
</section>
<section id="preparing-the-data-for-estimation" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data-for-estimation">3. Preparing the Data for Estimation</h2>
<p>The “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer <span class="math inline">\(i\)</span>, covariate <span class="math inline">\(k\)</span>, and product <span class="math inline">\(j\)</span>) instead of the typical 2 dimensions for cross-sectional regression models (consumer <span class="math inline">\(i\)</span> and covariate <span class="math inline">\(k\)</span>). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.</p>
<div id="637c0661" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.read_csv(<span class="st">"conjoint_data.csv"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode 'brand' and 'ad' columns (Hulu and ad-free are the baseline)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped <span class="op">=</span> pd.get_dummies(conjoint_data, columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"ad"</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a unique identifier for each choice set</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped[<span class="st">"choice_set"</span>] <span class="op">=</span> (</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    conjoint_data_prepped[<span class="st">"resp"</span>].astype(<span class="bu">str</span>) <span class="op">+</span> <span class="st">"_"</span> <span class="op">+</span> conjoint_data_prepped[<span class="st">"task"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the data</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped <span class="op">=</span> conjoint_data_prepped.sort_values(by<span class="op">=</span>[<span class="st">"resp"</span>, <span class="st">"task"</span>])</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">resp</th>
<th data-quarto-table-cell-role="th">task</th>
<th data-quarto-table-cell-role="th">choice</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">brand_N</th>
<th data-quarto-table-cell-role="th">brand_P</th>
<th data-quarto-table-cell-role="th">ad_Yes</th>
<th data-quarto-table-cell-role="th">choice_set</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>28</td>
<td>True</td>
<td>False</td>
<td>True</td>
<td>1_1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>16</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>1_1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>16</td>
<td>False</td>
<td>True</td>
<td>True</td>
<td>1_1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>32</td>
<td>True</td>
<td>False</td>
<td>True</td>
<td>1_2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>2</td>
<td>1</td>
<td>16</td>
<td>False</td>
<td>True</td>
<td>True</td>
<td>1_2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="estimation-via-maximum-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</h2>
<p>We estimated the coefficients of the multinomial logit model using Maximum Likelihood Estimation and summarized the results in a table. Each row in the table corresponds to one of the key variables: whether the brand was Netflix or Prime (with Hulu as the baseline), whether the option included ads, and the price of the plan. The column labeled “Estimate” shows how each variable influences the probability of being chosen. A positive value indicates that the feature makes an option more likely to be selected, while a negative value suggests the opposite. The standard errors show how precise these estimates are, and the 95% confidence intervals provide a range in which we expect the true values to fall. Since none of the intervals include zero, we conclude that all four variables have a statistically significant effect on choice. Overall, the estimates confirm that people tend to prefer Netflix and Prime over Hulu, dislike advertisements, and are less likely to choose higher-priced options. These results are consistent with expectations and provide clear evidence of how these product features shape consumer decisions.</p>
<div id="f7726f30" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract relevant columns</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> conjoint_data_prepped[[<span class="st">'brand_N'</span>, <span class="st">'brand_P'</span>, <span class="st">'ad_Yes'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice'</span>].values</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>choice_set_ids <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice_set'</span>].values</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-likelihood function</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_likelihood(beta):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta)  <span class="co"># Ensure beta is always a NumPy array</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'utility'</span>: utilities,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'choice'</span>: y,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'choice_set'</span>: choice_set_ids</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'exp_utility'</span>] <span class="op">=</span> np.exp(df[<span class="st">'utility'</span>].astype(<span class="bu">float</span>))  <span class="co"># Ensure float dtype</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'denominator'</span>] <span class="op">=</span> df.groupby(<span class="st">'choice_set'</span>)[<span class="st">'exp_utility'</span>].transform(<span class="st">'sum'</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'prob'</span>] <span class="op">=</span> df[<span class="st">'exp_utility'</span>] <span class="op">/</span> df[<span class="st">'denominator'</span>]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_prob'</span>] <span class="op">=</span> np.log(df[<span class="st">'prob'</span>])</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>df.loc[df[<span class="st">'choice'</span>] <span class="op">==</span> <span class="dv">1</span>, <span class="st">'log_prob'</span>].<span class="bu">sum</span>()</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>beta_init <span class="op">=</span> np.zeros(X.shape[<span class="dv">1</span>])</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Run optimization</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(log_likelihood, beta_init, method<span class="op">=</span><span class="st">'BFGS'</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract estimates and standard errors</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>mle_betas <span class="op">=</span> result.x</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>hessian_inv <span class="op">=</span> result.hess_inv</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>standard_errors <span class="op">=</span> np.sqrt(np.diag(hessian_inv))</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>conf_intervals <span class="op">=</span> np.vstack([</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    mle_betas <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> standard_errors,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    mle_betas <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> standard_errors</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>]).T</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="st">"Beta_Netflix"</span>, <span class="st">"Beta_Prime"</span>, <span class="st">"Beta_Ads"</span>, <span class="st">"Beta_Price"</span>]</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>mle_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Parameter"</span>: params,</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate"</span>: mle_betas,</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std. Error"</span>: standard_errors,</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Lower"</span>: conf_intervals[:, <span class="dv">0</span>],</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Upper"</span>: conf_intervals[:, <span class="dv">1</span>]</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>mle_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Parameter</th>
<th data-quarto-table-cell-role="th">Estimate</th>
<th data-quarto-table-cell-role="th">Std. Error</th>
<th data-quarto-table-cell-role="th">95% CI Lower</th>
<th data-quarto-table-cell-role="th">95% CI Upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Beta_Netflix</td>
<td>0.941195</td>
<td>0.118813</td>
<td>0.708322</td>
<td>1.174068</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Beta_Prime</td>
<td>0.501616</td>
<td>0.121461</td>
<td>0.263551</td>
<td>0.739680</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Beta_Ads</td>
<td>-0.731994</td>
<td>0.088667</td>
<td>-0.905782</td>
<td>-0.558207</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Beta_Price</td>
<td>-0.099480</td>
<td>0.006348</td>
<td>-0.111922</td>
<td>-0.087039</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="estimation-via-bayesian-methods" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</h2>
<p>We used a Bayesian approach to estimate the same four parameters from the multinomial logit model. This time, we applied a Metropolis-Hastings algorithm to draw samples from the posterior distribution, using weakly informative normal priors: N(0,5) for the binary variables and N(0,1) for the price coefficient. After discarding the initial 1,000 iterations as burn-in, we summarized the remaining 10,000 samples to calculate the posterior means, standard deviations, and 95% credible intervals.</p>
<p>The table of results looks very similar to what we obtained from the Maximum Likelihood Estimation in Section 4. For example, the posterior mean for <span class="math inline">\(\beta_\text{netflix}\)</span> was 0.946, very close to the MLE estimate of 0.941. The same pattern holds for the other parameters: the values are nearly identical, and the Bayesian credible intervals overlap substantially with the MLE confidence intervals. This consistency suggests that both estimation methods are providing stable and reliable insights. The slightly narrower standard deviations in the Bayesian results also suggest a modest gain in precision, likely due to the regularizing influence of the priors. Overall, the Bayesian approach confirms the key findings from the MLE: people prefer Netflix and Prime over Hulu, dislike ads, and are less likely to choose more expensive options.</p>
<div id="c06776d5" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> conjoint_data_prepped[[<span class="st">'brand_N'</span>, <span class="st">'brand_P'</span>, <span class="st">'ad_Yes'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice'</span>].values</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>choice_set_ids <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice_set'</span>].values</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode choice sets</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>group_ids <span class="op">=</span> LabelEncoder().fit_transform(choice_set_ids)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>num_sets <span class="op">=</span> group_ids.<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Build group mapping matrix</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>group_matrix <span class="op">=</span> np.zeros((num_sets, X.shape[<span class="dv">0</span>]))</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>group_matrix[group_ids, np.arange(X.shape[<span class="dv">0</span>])] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.asarray(X, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X.ndim <span class="op">==</span> <span class="dv">2</span> <span class="kw">and</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">4</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vectorized_log_likelihood(beta):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> beta.ndim <span class="op">!=</span> <span class="dv">1</span> <span class="kw">or</span> beta.shape[<span class="dv">0</span>] <span class="op">!=</span> <span class="dv">4</span>:</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"BAD BETA: </span><span class="sc">{</span>beta<span class="sc">}</span><span class="ss">, shape: </span><span class="sc">{</span>beta<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"beta must be a 1D array of length 4."</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(utilities, <span class="bu">float</span>):</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="st">"X @ beta returned a float. Check that X is a 2D NumPy array."</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    exp_util <span class="op">=</span> np.exp(utilities)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> group_matrix <span class="op">@</span> exp_util</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    prob <span class="op">=</span> exp_util <span class="op">/</span> denom[group_ids]</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(np.log(prob[y <span class="op">==</span> <span class="dv">1</span>]))</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-prior (Normal priors)</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(beta):</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    prior_sd <span class="op">=</span> np.array([<span class="fl">5.0</span>, <span class="fl">5.0</span>, <span class="fl">5.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>((beta <span class="op">/</span> prior_sd) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-posterior</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_posterior(beta):</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> vectorized_log_likelihood(beta) <span class="op">+</span> log_prior(beta)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Proposal SDs</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>proposal_sd <span class="op">=</span> np.array([<span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span>])</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Metropolis-Hastings MCMC</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metropolis_hastings(start, iterations, burn_in):</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    beta_current <span class="op">=</span> np.asarray(start)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>        proposal <span class="op">=</span> beta_current <span class="op">+</span> np.random.normal(<span class="dv">0</span>, proposal_sd)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>        log_alpha <span class="op">=</span> log_posterior(proposal) <span class="op">-</span> log_posterior(beta_current)</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.log(np.random.rand()) <span class="op">&lt;</span> log_alpha:</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>            beta_current <span class="op">=</span> proposal  <span class="co"># Accept</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;=</span> burn_in:</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>            samples.append(beta_current.copy())</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(samples)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Run MCMC</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>posterior_samples <span class="op">=</span> metropolis_hastings(start<span class="op">=</span>np.zeros(<span class="dv">4</span>), iterations<span class="op">=</span><span class="dv">11000</span>, burn_in<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>posterior_means <span class="op">=</span> posterior_samples.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>posterior_stds <span class="op">=</span> posterior_samples.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>posterior_cis <span class="op">=</span> np.percentile(posterior_samples, [<span class="fl">2.5</span>, <span class="fl">97.5</span>], axis<span class="op">=</span><span class="dv">0</span>).T</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="st">"Beta_Netflix"</span>, <span class="st">"Beta_Prime"</span>, <span class="st">"Beta_Ads"</span>, <span class="st">"Beta_Price"</span>]</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>bayes_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Parameter"</span>: params,</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Posterior Mean"</span>: posterior_means,</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std. Dev"</span>: posterior_stds,</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Lower"</span>: posterior_cis[:, <span class="dv">0</span>],</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Upper"</span>: posterior_cis[:, <span class="dv">1</span>]</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>bayes_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Parameter</th>
<th data-quarto-table-cell-role="th">Posterior Mean</th>
<th data-quarto-table-cell-role="th">Std. Dev</th>
<th data-quarto-table-cell-role="th">95% CI Lower</th>
<th data-quarto-table-cell-role="th">95% CI Upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Beta_Netflix</td>
<td>0.945757</td>
<td>0.112710</td>
<td>0.732071</td>
<td>1.170714</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Beta_Prime</td>
<td>0.506718</td>
<td>0.113585</td>
<td>0.288233</td>
<td>0.735044</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Beta_Ads</td>
<td>-0.732612</td>
<td>0.083074</td>
<td>-0.890905</td>
<td>-0.566756</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Beta_Price</td>
<td>-0.099754</td>
<td>0.006286</td>
<td>-0.111863</td>
<td>-0.087338</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="2d1111f8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>beta_idx <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>param_name <span class="op">=</span> <span class="st">"Beta_Netflix"</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_samples[:, beta_idx], color<span class="op">=</span><span class="st">"blue"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Trace Plot: </span><span class="sc">{</span>param_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Iteration"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.hist(posterior_samples[:, beta_idx], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">"skyblue"</span>, edgecolor<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Posterior Distribution: </span><span class="sc">{</span>param_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Value"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">6. Discussion</h2>
<section id="interpreting-parameter-estimates" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-parameter-estimates">Interpreting Parameter Estimates</h3>
<p>Even if we didn’t simulate the data ourselves, we can still learn a lot from the parameter estimates we got. For example, the fact that <span class="math inline">\(\beta_\text{Netflix} &gt; \beta_\text{Prime}\)</span> means that, on average, people in our sample liked Netflix more than Prime. Since Hulu was the baseline (omitted category), this also tells us that Prime was preferred over Hulu, but not as much as Netflix. So in terms of overall appeal, Netflix came out on top.</p>
<p>We also saw that the estimate for <span class="math inline">\(\beta_\text{price}\)</span> was negative. This is what we expect: as the price of a streaming plan goes up, people are less likely to choose it. That makes sense since higher prices usually make a product less attractive.</p>
<p>The estimate for the ad variable was also negative. This means that people don’t like having ads in their streaming experience. Given the choice, they’re more likely to pick a service that is ad-free.</p>
<p>Overall, all of our parameter estimates line up well with what we would expect based on common sense. People prefer Netflix, dislike ads, and try to avoid higher prices.</p>
</section>
<section id="toward-a-multi-level-hierarchical-model" class="level3">
<h3 class="anchored" data-anchor-id="toward-a-multi-level-hierarchical-model">Toward a Multi-Level (Hierarchical) Model</h3>
<p>In real-world data, not everyone values things the same way. Some people may care a lot about price, while others focus more on the brand or whether the service has ads. A single set of average parameters doesn’t always capture this variation.</p>
<p>A multi-level model helps us deal with that. Instead of assuming everyone shares the same preferences, this model assumes each person has their own set of part-worth utilities (or <span class="math inline">\(\beta\)</span> values). These individual-level betas come from a larger population distribution, usually assumed to be normal:</p>
<p>This means that we treat <span class="math inline">\(\mu\)</span> as the average preference across people, and <span class="math inline">\(\Sigma\)</span> captures how much people vary in their preferences.</p>
<p>If we wanted to simulate data under this kind of model, we would first draw a <span class="math inline">\(\beta\)</span> vector for each person from a multivariate normal distribution. Then we would use that <span class="math inline">\(\beta_i\)</span> to simulate choices for that specific person. This lets us build realistic datasets where everyone thinks a little differently.</p>
<p>Estimating these models is a bit more advanced. We often use Bayesian methods like Gibbs sampling or Hamiltonian Monte Carlo (HMC), or we use simulated maximum likelihood in a frequentist framework. These methods take more time and computing power, but they allow us to capture much richer information from our data.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Multinomial Logit Model"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Jun Zhu Li"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#callout-appearance: minimal</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm. </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. Likelihood for the Multi-nomial Logit (MNL) Model</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>Suppose we have $i=1,\ldots,n$ consumers who each select exactly one product $j$ from a set of $J$ products. The outcome variable is the identity of the product chosen $y_i \in <span class="sc">\{</span>1, \ldots, J<span class="sc">\}</span>$ or equivalently a vector of $J-1$ zeros and $1$ one, where the $1$ indicates the selected product. For example, if the third product was chosen out of 3 products, then either $y=3$ or $y=(0,0,1)$ depending on how we want to represent it. Suppose also that we have a vector of data on each product $x_j$ (eg, brand, price, etc.). </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>We model the consumer's decision as the selection of the product that provides the most utility, and we'll specify the utility function as a linear function of the product characteristics:</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>$$ U_{ij} = x_j'\beta + \epsilon_{ij} $$</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>where $\epsilon_{ij}$ is an i.i.d. extreme value error term. </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer $i$ chooses product $j$:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>$$ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>For example, if there are 3 products, the probability that consumer $i$ chooses product 3 is:</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>$$ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} $$</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>A clever way to write the individual likelihood function for consumer $i$ is the product of the $J$ probabilities, each raised to the power of an indicator variable ($\delta_{ij}$) that indicates the chosen product:</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>$$ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}$$</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>Notice that if the consumer selected product $j=3$, then $\delta_{i3}=1$ while $\delta_{i1}=\delta_{i2}=0$ and the likelihood is:</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>$$ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} $$</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>The joint likelihood (across all consumers) is the product of the $n$ individual likelihoods:</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>$$ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} $$</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>And the joint log-likelihood function is:</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>$$ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) $$</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. Simulate Conjoint Data</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>We will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a "no choice" option; each simulated respondent must select one of the 3 alternatives. </span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>Each alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from \$4 to \$32 in increments of \$4.</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>The part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer $i$ for hypothethical streaming service $j$ is </span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>u_{ij} = (1 \times Netflix_j) + (0.5 \times Prime_j) + (-0.8*Ads_j) - 0.1\times Price_j + \varepsilon_{ij}</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>where the variables are binary indicators and $\varepsilon$ is Type 1 Extreme Value (ie, Gumble) distributed.</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>The following code provides the simulation of the conjoint data.</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>:::: {.callout-note collapse="true"}</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a><span class="co"># set seed for reproducibility</span></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="co"># define attributes</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>brand <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"N"</span>, <span class="st">"P"</span>, <span class="st">"H"</span>) <span class="co"># Netflix, Prime, Hulu</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>ad <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>price <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">8</span>, <span class="dv">32</span>, <span class="at">by=</span><span class="dv">4</span>)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a><span class="co"># generate all possible profiles</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>profiles <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>    <span class="at">brand =</span> brand,</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>    <span class="at">ad =</span> ad,</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>    <span class="at">price =</span> price</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">nrow</span>(profiles)</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="co"># assign part-worth utilities (true parameters)</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>b_util <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">N =</span> <span class="fl">1.0</span>, <span class="at">P =</span> <span class="fl">0.5</span>, <span class="at">H =</span> <span class="dv">0</span>)</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>a_util <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">Yes =</span> <span class="sc">-</span><span class="fl">0.8</span>, <span class="at">No =</span> <span class="fl">0.0</span>)</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>p_util <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="sc">-</span><span class="fl">0.1</span> <span class="sc">*</span> p</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a><span class="co"># number of respondents, choice tasks, and alternatives per task</span></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>n_peeps <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>n_tasks <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>n_alts <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a><span class="co"># function to simulate one respondent’s data</span></span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>sim_one <span class="ot">&lt;-</span> <span class="cf">function</span>(id) {</span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>    datlist <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over choice tasks</span></span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_tasks) {</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># randomly sample 3 alts (better practice would be to use a design)</span></span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>        dat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">resp=</span>id, <span class="at">task=</span>t, profiles[<span class="fu">sample</span>(m, <span class="at">size=</span>n_alts), ])</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute deterministic portion of utility</span></span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>        dat<span class="sc">$</span>v <span class="ot">&lt;-</span> b_util[dat<span class="sc">$</span>brand] <span class="sc">+</span> a_util[dat<span class="sc">$</span>ad] <span class="sc">+</span> <span class="fu">p_util</span>(dat<span class="sc">$</span>price) <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">10</span>)</span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add Gumbel noise (Type I extreme value)</span></span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a>        dat<span class="sc">$</span>e <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">log</span>(<span class="sc">-</span><span class="fu">log</span>(<span class="fu">runif</span>(n_alts)))</span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a>        dat<span class="sc">$</span>u <span class="ot">&lt;-</span> dat<span class="sc">$</span>v <span class="sc">+</span> dat<span class="sc">$</span>e</span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># identify chosen alternative</span></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>        dat<span class="sc">$</span>choice <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(dat<span class="sc">$</span>u <span class="sc">==</span> <span class="fu">max</span>(dat<span class="sc">$</span>u))</span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># store task</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>        datlist[[t]] <span class="ot">&lt;-</span> dat</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># combine all tasks for one respondent</span></span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>    <span class="fu">do.call</span>(rbind, datlist)</span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate data for all respondents</span></span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="ot">&lt;-</span> <span class="fu">do.call</span>(rbind, <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>n_peeps, sim_one))</span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a><span class="co"># remove values unobservable to the researcher</span></span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="ot">&lt;-</span> conjoint_data[ , <span class="fu">c</span>(<span class="st">"resp"</span>, <span class="st">"task"</span>, <span class="st">"brand"</span>, <span class="st">"ad"</span>, <span class="st">"price"</span>, <span class="st">"choice"</span>)]</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a><span class="co"># clean up</span></span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">setdiff</span>(<span class="fu">ls</span>(), <span class="st">"conjoint_data"</span>))</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. Preparing the Data for Estimation</span></span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a>The "hard part" of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer $i$, covariate $k$, and product $j$) instead of the typical 2 dimensions for cross-sectional regression models (consumer $i$ and covariate $k$). The fact that each task for each respondent has the same number of alternatives (3) helps.  In addition, we need to convert the categorical variables for brand and ads into binary variables.</span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.read_csv(<span class="st">"conjoint_data.csv"</span>)</span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode 'brand' and 'ad' columns (Hulu and ad-free are the baseline)</span></span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped <span class="op">=</span> pd.get_dummies(conjoint_data, columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"ad"</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a unique identifier for each choice set</span></span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped[<span class="st">"choice_set"</span>] <span class="op">=</span> (</span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a>    conjoint_data_prepped[<span class="st">"resp"</span>].astype(<span class="bu">str</span>) <span class="op">+</span> <span class="st">"_"</span> <span class="op">+</span> conjoint_data_prepped[<span class="st">"task"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the data</span></span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped <span class="op">=</span> conjoint_data_prepped.sort_values(by<span class="op">=</span>[<span class="st">"resp"</span>, <span class="st">"task"</span>])</span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>conjoint_data_prepped.head()</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. Estimation via Maximum Likelihood</span></span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a>We estimated the coefficients of the multinomial logit model using Maximum Likelihood Estimation and summarized the results in a table. Each row in the table corresponds to one of the key variables: whether the brand was Netflix or Prime (with Hulu as the baseline), whether the option included ads, and the price of the plan. The column labeled "Estimate" shows how each variable influences the probability of being chosen. A positive value indicates that the feature makes an option more likely to be selected, while a negative value suggests the opposite. The standard errors show how precise these estimates are, and the 95% confidence intervals provide a range in which we expect the true values to fall. Since none of the intervals include zero, we conclude that all four variables have a statistically significant effect on choice. Overall, the estimates confirm that people tend to prefer Netflix and Prime over Hulu, dislike advertisements, and are less likely to choose higher-priced options. These results are consistent with expectations and provide clear evidence of how these product features shape consumer decisions.</span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract relevant columns</span></span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> conjoint_data_prepped[[<span class="st">'brand_N'</span>, <span class="st">'brand_P'</span>, <span class="st">'ad_Yes'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice'</span>].values</span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a>choice_set_ids <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice_set'</span>].values</span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-likelihood function</span></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_likelihood(beta):</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta)  <span class="co"># Ensure beta is always a NumPy array</span></span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a>    utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>        <span class="st">'utility'</span>: utilities,</span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>        <span class="st">'choice'</span>: y,</span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a>        <span class="st">'choice_set'</span>: choice_set_ids</span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'exp_utility'</span>] <span class="op">=</span> np.exp(df[<span class="st">'utility'</span>].astype(<span class="bu">float</span>))  <span class="co"># Ensure float dtype</span></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'denominator'</span>] <span class="op">=</span> df.groupby(<span class="st">'choice_set'</span>)[<span class="st">'exp_utility'</span>].transform(<span class="st">'sum'</span>)</span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'prob'</span>] <span class="op">=</span> df[<span class="st">'exp_utility'</span>] <span class="op">/</span> df[<span class="st">'denominator'</span>]</span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_prob'</span>] <span class="op">=</span> np.log(df[<span class="st">'prob'</span>])</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>df.loc[df[<span class="st">'choice'</span>] <span class="op">==</span> <span class="dv">1</span>, <span class="st">'log_prob'</span>].<span class="bu">sum</span>()</span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a>beta_init <span class="op">=</span> np.zeros(X.shape[<span class="dv">1</span>])</span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a><span class="co"># Run optimization</span></span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(log_likelihood, beta_init, method<span class="op">=</span><span class="st">'BFGS'</span>)</span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract estimates and standard errors</span></span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a>mle_betas <span class="op">=</span> result.x</span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>hessian_inv <span class="op">=</span> result.hess_inv</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>standard_errors <span class="op">=</span> np.sqrt(np.diag(hessian_inv))</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a>conf_intervals <span class="op">=</span> np.vstack([</span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>    mle_betas <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> standard_errors,</span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>    mle_betas <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> standard_errors</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a>]).T</span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="st">"Beta_Netflix"</span>, <span class="st">"Beta_Prime"</span>, <span class="st">"Beta_Ads"</span>, <span class="st">"Beta_Price"</span>]</span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a>mle_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Parameter"</span>: params,</span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate"</span>: mle_betas,</span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std. Error"</span>: standard_errors,</span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Lower"</span>: conf_intervals[:, <span class="dv">0</span>],</span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Upper"</span>: conf_intervals[:, <span class="dv">1</span>]</span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a>mle_results</span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. Estimation via Bayesian Methods</span></span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a>We used a Bayesian approach to estimate the same four parameters from the multinomial logit model. This time, we applied a Metropolis-Hastings algorithm to draw samples from the posterior distribution, using weakly informative normal priors: N(0,5) for the binary variables and N(0,1) for the price coefficient. After discarding the initial 1,000 iterations as burn-in, we summarized the remaining 10,000 samples to calculate the posterior means, standard deviations, and 95% credible intervals.</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a>The table of results looks very similar to what we obtained from the Maximum Likelihood Estimation in Section 4. For example, the posterior mean for $\beta_\text{netflix}$ was 0.946, very close to the MLE estimate of 0.941. The same pattern holds for the other parameters: the values are nearly identical, and the Bayesian credible intervals overlap substantially with the MLE confidence intervals. This consistency suggests that both estimation methods are providing stable and reliable insights. The slightly narrower standard deviations in the Bayesian results also suggest a modest gain in precision, likely due to the regularizing influence of the priors. Overall, the Bayesian approach confirms the key findings from the MLE: people prefer Netflix and Prime over Hulu, dislike ads, and are less likely to choose more expensive options.</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> conjoint_data_prepped[[<span class="st">'brand_N'</span>, <span class="st">'brand_P'</span>, <span class="st">'ad_Yes'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice'</span>].values</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a>choice_set_ids <span class="op">=</span> conjoint_data_prepped[<span class="st">'choice_set'</span>].values</span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode choice sets</span></span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a>group_ids <span class="op">=</span> LabelEncoder().fit_transform(choice_set_ids)</span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>num_sets <span class="op">=</span> group_ids.<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Build group mapping matrix</span></span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a>group_matrix <span class="op">=</span> np.zeros((num_sets, X.shape[<span class="dv">0</span>]))</span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a>group_matrix[group_ids, np.arange(X.shape[<span class="dv">0</span>])] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.asarray(X, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X.ndim <span class="op">==</span> <span class="dv">2</span> <span class="kw">and</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">4</span></span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vectorized_log_likelihood(beta):</span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> beta.ndim <span class="op">!=</span> <span class="dv">1</span> <span class="kw">or</span> beta.shape[<span class="dv">0</span>] <span class="op">!=</span> <span class="dv">4</span>:</span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"BAD BETA: </span><span class="sc">{</span>beta<span class="sc">}</span><span class="ss">, shape: </span><span class="sc">{</span>beta<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"beta must be a 1D array of length 4."</span>)</span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a>    utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(utilities, <span class="bu">float</span>):</span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="st">"X @ beta returned a float. Check that X is a 2D NumPy array."</span>)</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a>    exp_util <span class="op">=</span> np.exp(utilities)</span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> group_matrix <span class="op">@</span> exp_util</span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a>    prob <span class="op">=</span> exp_util <span class="op">/</span> denom[group_ids]</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(np.log(prob[y <span class="op">==</span> <span class="dv">1</span>]))</span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-prior (Normal priors)</span></span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(beta):</span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta)</span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>    prior_sd <span class="op">=</span> np.array([<span class="fl">5.0</span>, <span class="fl">5.0</span>, <span class="fl">5.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>((beta <span class="op">/</span> prior_sd) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-posterior</span></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_posterior(beta):</span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> vectorized_log_likelihood(beta) <span class="op">+</span> log_prior(beta)</span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a><span class="co"># Proposal SDs</span></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a>proposal_sd <span class="op">=</span> np.array([<span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span>])</span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a><span class="co"># Metropolis-Hastings MCMC</span></span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metropolis_hastings(start, iterations, burn_in):</span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a>    beta_current <span class="op">=</span> np.asarray(start)</span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a>        proposal <span class="op">=</span> beta_current <span class="op">+</span> np.random.normal(<span class="dv">0</span>, proposal_sd)</span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a>        log_alpha <span class="op">=</span> log_posterior(proposal) <span class="op">-</span> log_posterior(beta_current)</span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.log(np.random.rand()) <span class="op">&lt;</span> log_alpha:</span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a>            beta_current <span class="op">=</span> proposal  <span class="co"># Accept</span></span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;=</span> burn_in:</span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>            samples.append(beta_current.copy())</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(samples)</span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a><span class="co"># Run MCMC</span></span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a>posterior_samples <span class="op">=</span> metropolis_hastings(start<span class="op">=</span>np.zeros(<span class="dv">4</span>), iterations<span class="op">=</span><span class="dv">11000</span>, burn_in<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a>posterior_means <span class="op">=</span> posterior_samples.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>posterior_stds <span class="op">=</span> posterior_samples.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>posterior_cis <span class="op">=</span> np.percentile(posterior_samples, [<span class="fl">2.5</span>, <span class="fl">97.5</span>], axis<span class="op">=</span><span class="dv">0</span>).T</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="st">"Beta_Netflix"</span>, <span class="st">"Beta_Prime"</span>, <span class="st">"Beta_Ads"</span>, <span class="st">"Beta_Price"</span>]</span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a>bayes_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Parameter"</span>: params,</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Posterior Mean"</span>: posterior_means,</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std. Dev"</span>: posterior_stds,</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Lower"</span>: posterior_cis[:, <span class="dv">0</span>],</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>    <span class="st">"95% CI Upper"</span>: posterior_cis[:, <span class="dv">1</span>]</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>bayes_results</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>beta_idx <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a>param_name <span class="op">=</span> <span class="st">"Beta_Netflix"</span></span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_samples[:, beta_idx], color<span class="op">=</span><span class="st">"blue"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Trace Plot: </span><span class="sc">{</span>param_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Iteration"</span>)</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a>plt.hist(posterior_samples[:, beta_idx], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">"skyblue"</span>, edgecolor<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Posterior Distribution: </span><span class="sc">{</span>param_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Value"</span>)</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6. Discussion</span></span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpreting Parameter Estimates</span></span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>Even if we didn’t simulate the data ourselves, we can still learn a lot from the parameter estimates we got. For example, the fact that $\beta_\text{Netflix} &gt; \beta_\text{Prime}$ means that, on average, people in our sample liked Netflix more than Prime. Since Hulu was the baseline (omitted category), this also tells us that Prime was preferred over Hulu, but not as much as Netflix. So in terms of overall appeal, Netflix came out on top.</span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>We also saw that the estimate for $\beta_\text{price}$ was negative. This is what we expect: as the price of a streaming plan goes up, people are less likely to choose it. That makes sense since higher prices usually make a product less attractive.</span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a>The estimate for the ad variable was also negative. This means that people don’t like having ads in their streaming experience. Given the choice, they’re more likely to pick a service that is ad-free.</span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>Overall, all of our parameter estimates line up well with what we would expect based on common sense. People prefer Netflix, dislike ads, and try to avoid higher prices.</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### Toward a Multi-Level (Hierarchical) Model</span></span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a>In real-world data, not everyone values things the same way. Some people may care a lot about price, while others focus more on the brand or whether the service has ads. A single set of average parameters doesn’t always capture this variation.</span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a>A multi-level model helps us deal with that. Instead of assuming everyone shares the same preferences, this model assumes each person has their own set of part-worth utilities (or $\beta$ values). These individual-level betas come from a larger population distribution, usually assumed to be normal:</span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a>This means that we treat $\mu$ as the average preference across people, and $\Sigma$ captures how much people vary in their preferences.</span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a>If we wanted to simulate data under this kind of model, we would first draw a $\beta$ vector for each person from a multivariate normal distribution. Then we would use that $\beta_i$ to simulate choices for that specific person. This lets us build realistic datasets where everyone thinks a little differently.</span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a>Estimating these models is a bit more advanced. We often use Bayesian methods like Gibbs sampling or Hamiltonian Monte Carlo (HMC), or we use simulated maximum likelihood in a frequentist framework. These methods take more time and computing power, but they allow us to capture much richer information from our data.</span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>